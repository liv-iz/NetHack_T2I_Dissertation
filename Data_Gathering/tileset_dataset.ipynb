{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # library for data analysis\n",
    "import requests # library to handle requests\n",
    "import logging # library to handle logging\n",
    "from bs4 import BeautifulSoup # library to parse HTML documents\n",
    "import requests # library to handle requests\n",
    "from tqdm import tqdm # library to display progress bar\n",
    "from requests.exceptions import Timeout # library to handle timeout exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(filename='app.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "# Make a request to the website\n",
    "logging.info('Making request to website')\n",
    "url = \"https://nethackwiki.com/wiki/List_of_vanilla_NetHack_tiles\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "logging.info('Parsing HTML content')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all img tags\n",
    "logging.info('Finding img tags')\n",
    "img_tags = soup.find_all('img')\n",
    "\n",
    "# Initialize lists to store the data\n",
    "titles = []\n",
    "hrefs = []\n",
    "srcs = []\n",
    "\n",
    "# Loop through the img tags and extract the data\n",
    "logging.info('Extracting data from img tags')\n",
    "for img in img_tags:\n",
    "    if 'png' in img['src']:\n",
    "        titles.append(img.get('alt'))\n",
    "        hrefs.append(img.parent.get('href'))\n",
    "        srcs.append(img.get('src'))\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "logging.info('Creating DataFrame')\n",
    "tileset= pd.DataFrame({\n",
    "    'Title': titles,\n",
    "    'Wiki_link': hrefs,\n",
    "    'Image_link': srcs\n",
    "})\n",
    "\n",
    "#Replace the .png in the Title column\n",
    "logging.info('Replacing .png in Title column')\n",
    "tileset['Title'].replace('.png', '', regex=True, inplace=True)\n",
    "\n",
    "#Save to csv file\n",
    "logging.info('Saving DataFrame to CSV file')\n",
    "tileset.to_csv('tileset_vanilla.csv', index=False)\n",
    "\n",
    "logging.info('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://nethackwiki.com/wiki/Tileset\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the map with name 'ImageMap_1_514738766'\n",
    "image_map = soup.find('map', {'name': 'ImageMap_1_2102875891'})\n",
    "\n",
    "# Find all areas in the map\n",
    "areas = image_map.find_all('area')\n",
    "\n",
    "# Extract the href, alt, and title attributes of each area\n",
    "area_data = []\n",
    "for area in areas:\n",
    "    Tile_description = area.get('alt')\n",
    "    Tile_name = area.get('title')\n",
    "    description_link = area.get('href')\n",
    "    area_data.append({'Tile_name': Tile_name, 'Tile_description': Tile_description, 'description_link': description_link})\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "tileset_from_map = pd.DataFrame(area_data)\n",
    "\n",
    "\n",
    "#If the string in Tile_name contains 'statue' then delete row\n",
    "for index, row in tileset_from_map.iterrows():\n",
    "    if 'statue' in row['Tile_name']:\n",
    "        tileset_from_map.drop(index, inplace=True)\n",
    "\n",
    "#For all strings in the description_link add the base_wikiurl\n",
    "tileset_from_map['description_link'] = tileset_from_map['description_link'].apply(lambda x: f\"https://nethackwiki.com{x}\" if x is not None else None)\n",
    "\n",
    "tileset_from_map.to_csv('tileset_from_map.csv', index=False)\n",
    "\n",
    "\n",
    "tileset_with_links=pd.read_csv('tileset_from_map.csv')\n",
    "tileset_with_links['Tile_name'] = tileset_with_links['Tile_name'].str.replace(' ', '_').replace('_(monster)', '')\n",
    "\n",
    "def find_image(tile_name, url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        img_tags = soup.find_all('img')\n",
    "        for img in img_tags:\n",
    "            if 'png' in img['src'] and tile_name in img['src']:\n",
    "                return img['src']\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "tileset_with_links['Tile_name'] = tileset_with_links['Tile_name'].str.replace('_(monster)', '')\n",
    "tileset_with_links['Tile_name'] = tileset_with_links['Tile_name'].str.capitalize()\n",
    "# Initialize a progress bar\n",
    "pbar = tqdm(total=tileset_with_links.shape[0])\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "for i, row in tileset_with_links.iterrows():\n",
    "    if pd.isnull(row['image_link']):\n",
    "        tile_name = row['Tile_name']\n",
    "        url = 'https://nethackwiki.com/wiki/List_of_vanilla_NetHack_tiles'\n",
    "        img_src = find_image(tile_name, url)\n",
    "        if img_src is None:\n",
    "            print(f\"No image found for tile_name: {tile_name}\")\n",
    "        else:\n",
    "            tileset_with_links.at[i, 'image_link'] = img_src\n",
    "    pbar.update()\n",
    "\n",
    "# Close the progress bar\n",
    "pbar.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nethack_tileset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
